{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TNEHQlWO4t2a"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_key = userdata.get(\"mistral_key\")"
      ],
      "metadata": {
        "id": "QXLO2WXo46fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mistralai"
      ],
      "metadata": {
        "id": "vcgtMWjO47C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from mistralai import Mistral"
      ],
      "metadata": {
        "id": "e4Dg-cGl48TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_model =  Mistral(api_key=mistral_key)"
      ],
      "metadata": {
        "id": "bSuKP2nt4-jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_to_dictionary(csv_file):\n",
        "  import pandas as pd\n",
        "  f = pd.read_csv(csv_file)\n",
        "  prompts = f.iloc[:,0].tolist()\n",
        "  generations = f.iloc[:,1].tolist()\n",
        "  return prompts, generations"
      ],
      "metadata": {
        "id": "3eCXBNxc5AK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ground_truth(prompt,conversation):\n",
        "  model_name = \"mistral-large-latest\"\n",
        "  chat_response = mistral_model.chat.complete(model = model_name,\n",
        "      messages = [\n",
        "          {\n",
        "                \"role\": \"user\",\n",
        "                \"content\":  \"\"\"You are a legal analysis assistant tasked with identifying elements of a crime in a conversation.\n",
        "\n",
        "### Instructions:\n",
        "1. Given a conversation between multiple participants, extract all messages that indicate elements of a crime.\n",
        "2. Focus on:\n",
        "   - **Guilty Act (Actus Reus):** Actions that constitute a crime.\n",
        "   - **Guilty Mind (Mens Rea):** Intent, recklessness, or knowledge of wrongdoing.\n",
        "   - **Causation:** Any messages linking an act to its consequences.\n",
        "   - **Concurrence:** Statements indicating intent and action happening together.\n",
        "   - **Other Crime Indicators:** Admissions of guilt, discussions of criminal planning, or direct/indirect confessions.\n",
        "\n",
        "### Input Format:\n",
        "- You will receive a JSON object containing:\n",
        "  - \"prompt\": The original prompt given to generate the conversation.\n",
        "  - \"conversation\": A list of messages in chronological order.\n",
        "\n",
        "### Output Format:\n",
        "- Return a JSON object with:\n",
        "  - \"ground_truth\": A list of messages that contain crime-related elements.\n",
        "\n",
        "---\n",
        "\n",
        "**Input:**\n",
        "{\n",
        "  \"prompt\": \"{PLACEHOLDER_FOR_PROMPT}\",\n",
        "  \"conversation\": {PLACEHOLDER_FOR_CONVERSATION}\n",
        "}\n",
        "\n",
        "**Output:**\n",
        "{\n",
        "  \"ground_truth\": {PLACEHOLDER_FOR_GROUND_TRUTH}\n",
        "}\n",
        "\n",
        "---\n",
        "\n",
        "**Now, process the input conversation and return the \"ground_truth\" messages as a JSON object.**\"\"\"\n",
        ".format(prompt,conversation)\n",
        "            },\n",
        "      ]\n",
        "  )\n",
        "  return chat_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "V0SAAb3H5Bie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts, generations = csv_to_dictionary(\"/content/true_positives_conversations.csv\")"
      ],
      "metadata": {
        "id": "VvVZ7J-r5I9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truths = []\n",
        "for i in range(50,101):\n",
        "  answer = generate_ground_truth(prompts[i], generations[i])\n",
        "  answers.append(answer)\n",
        "  print(\"{} th done\".format(i+1))\n",
        "  time.sleep(30)"
      ],
      "metadata": {
        "id": "pS7mcbS75Lw0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}