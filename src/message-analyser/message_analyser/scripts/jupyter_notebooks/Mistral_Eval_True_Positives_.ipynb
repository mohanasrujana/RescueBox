{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJRGuOTc--50"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsLzIsmL_I19"
      },
      "outputs": [],
      "source": [
        "mistral_key = userdata.get(\"mistral_key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiTNpNxSAZec",
        "outputId": "1642908f-8bdf-43bb-c606-fdc33e53f29a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-1.6.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.10.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.8.2)\n",
            "Collecting typing-inspection>=0.4.0 (from mistralai)\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Downloading mistralai-1.6.0-py3-none-any.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: typing-inspection, eval-type-backport, mistralai\n",
            "Successfully installed eval-type-backport-0.2.2 mistralai-1.6.0 typing-inspection-0.4.0\n"
          ]
        }
      ],
      "source": [
        "! pip install mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLK9eTHf_Oab"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from mistralai import Mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YALroZF7AmWD"
      },
      "outputs": [],
      "source": [
        "mistral_model =  Mistral(api_key=mistral_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Es3qlomCPix"
      },
      "outputs": [],
      "source": [
        "def evaluate_prompt(prompt,conversation):\n",
        "  model_name = \"mistral-large-latest\"\n",
        "  chat_response = mistral_model.chat.complete(model = model_name,\n",
        "      messages = [\n",
        "          {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"\"\"\n",
        "Evaluate the following conversation based on the given prompt.\n",
        "\n",
        "### Prompt:\n",
        "{}\n",
        "\n",
        "### Generated Conversation:\n",
        "{}\n",
        "\n",
        "Answer each question with **only** \"Yes\" or \"No\", each on a **new line**, without any extra text:\n",
        "\n",
        "1. Does the conversation align well with the intent and key aspects of the prompt?\n",
        "2. Are all major elements from the prompt reflected in the response?\n",
        "3. Does the conversation follow a coherent and logical sequence?\n",
        "4. Are the interactions structured in a way that makes sense narratively?\n",
        "5. Are crime-related aspects present in the generated conversation?\n",
        "6. Does the text include elements such as investigation, crime scenes, criminal activity, or law enforcement?\n",
        "\"\"\".format(prompt,conversation)\n",
        "            },\n",
        "      ]\n",
        "  )\n",
        "  return chat_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVL01Dr0E1Ok"
      },
      "outputs": [],
      "source": [
        "def csv_to_dictionary(csv_file):\n",
        "  import pandas as pd\n",
        "  f = pd.read_csv(csv_file)\n",
        "  prompts = f.iloc[:,0].tolist()\n",
        "  generations = f.iloc[:,1].tolist()\n",
        "  return prompts, generations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnBKDRiu7Or_"
      },
      "outputs": [],
      "source": [
        "prompts, generations = csv_to_dictionary(\"/content/true_positives_conversations.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUgAUD-k7Zfm",
        "outputId": "5af8cd3a-7127-4813-a49d-efc9bb02dd36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200, 200)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(prompts),len(generations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2b_UWWn_GI9"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "adAlblz07cYu",
        "outputId": "283f7211-13a5-48ce-d1d2-2c429ff1c8cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51 th evaluation done\n",
            "52 th evaluation done\n",
            "53 th evaluation done\n",
            "54 th evaluation done\n",
            "55 th evaluation done\n",
            "56 th evaluation done\n",
            "57 th evaluation done\n",
            "58 th evaluation done\n",
            "59 th evaluation done\n",
            "60 th evaluation done\n",
            "61 th evaluation done\n",
            "62 th evaluation done\n",
            "63 th evaluation done\n",
            "64 th evaluation done\n",
            "65 th evaluation done\n",
            "66 th evaluation done\n",
            "67 th evaluation done\n",
            "68 th evaluation done\n",
            "69 th evaluation done\n",
            "70 th evaluation done\n",
            "71 th evaluation done\n",
            "72 th evaluation done\n",
            "73 th evaluation done\n",
            "74 th evaluation done\n",
            "75 th evaluation done\n",
            "76 th evaluation done\n",
            "77 th evaluation done\n",
            "78 th evaluation done\n",
            "79 th evaluation done\n",
            "80 th evaluation done\n",
            "81 th evaluation done\n",
            "82 th evaluation done\n",
            "83 th evaluation done\n",
            "84 th evaluation done\n",
            "85 th evaluation done\n",
            "86 th evaluation done\n",
            "87 th evaluation done\n",
            "88 th evaluation done\n",
            "89 th evaluation done\n",
            "90 th evaluation done\n",
            "91 th evaluation done\n",
            "92 th evaluation done\n",
            "93 th evaluation done\n",
            "94 th evaluation done\n",
            "95 th evaluation done\n",
            "96 th evaluation done\n",
            "97 th evaluation done\n",
            "98 th evaluation done\n",
            "99 th evaluation done\n",
            "100 th evaluation done\n",
            "101 th evaluation done\n"
          ]
        }
      ],
      "source": [
        "answers = []\n",
        "for i in range(50,101):\n",
        "  answer = evaluate_prompt(prompts[i], generations[i])\n",
        "  answers.append(answer)\n",
        "  print(\"{} th evaluation done\".format(i+1))\n",
        "  time.sleep(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN3Oktkn86Nc",
        "outputId": "f31f5474-750e-422a-fa19-cf2c8c0706ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0D_kU50HwQ4"
      },
      "outputs": [],
      "source": [
        "def list_to_csv(list_,filename):\n",
        "  import pandas as pd\n",
        "  df = pd.DataFrame(list_)\n",
        "  df.to_csv(filename,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNHctR1iH4P-"
      },
      "outputs": [],
      "source": [
        "list_to_csv(answers,\"eval_part_1\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}