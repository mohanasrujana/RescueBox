{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_key = userdata.get('gemini_key')"
      ],
      "metadata": {
        "id": "CmsDBf4eiN6H"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "random.seed(28)\n",
        "import json\n",
        "import csv"
      ],
      "metadata": {
        "id": "3ryCUEnFiXdR"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2Ug1MNhieP54"
      },
      "outputs": [],
      "source": [
        "def gemini_setup(api_key):\n",
        "    os.system(\"pip install -q -U google-generativeai\")\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=gemini_key)\n",
        "    glm_config = genai.GenerationConfig(temperature=0.99)\n",
        "    safety_settings = [\n",
        "        {\"category\": \"HARM_CATEGORY_DANGEROUS\", \"threshold\": \"BLOCK_NONE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "    ]\n",
        "    gemini_model = genai.GenerativeModel('gemini-2.0-flash', generation_config=glm_config, safety_settings=safety_settings)\n",
        "    return gemini_model\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLJTYyIIhXsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_model = gemini_setup(gemini_key)"
      ],
      "metadata": {
        "id": "9HtMh_-UhCSl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question Generation Pipeline"
      ],
      "metadata": {
        "id": "dbtgOmoo38c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt():\n",
        "  prompt_text = f\"\"\"\n",
        "  You are a legal expert designing investigative questions for analyzing crime-related conversations. Your task is to design investigative questions for extracting specific evidence from crime-related conversations. The crime in question here is murder.\n",
        "\n",
        "  Generate 100 questions that:\n",
        "  Are designed to retrieve direct text messages from a conversation.\n",
        "  Do not assume any names, times, locations, or methods.\n",
        "  Are framed to help investigators uncover critical details through careful questioning.\n",
        "  Are clear, specific, and structured to return direct messages, not summaries or opinions.\n",
        "\n",
        "  The questions should be focused on uncovering elements of a crime, including:\n",
        "  Actus Reus (Guilty Act) – What actions were taken? How did they lead to harm?\n",
        "  Mens Rea (Guilty Mind) – What was the intent behind the act? Was it planned or spontaneous?\n",
        "  Causation – How did the event lead to harm? Were there external factors involved?\n",
        "  Concurrence – Did intent and action happen together?\n",
        "  Attempt & Conspiracy – Was the crime planned but not carried out?\n",
        "  Possible Defenses – Could there be self-defense or mitigating circumstances?\n",
        "\n",
        "  Example questions:\n",
        "  \"Show me messages in which one person asks about another person's age.\"\n",
        "  \"Extract all messages that mention someone's age.\"\n",
        "  \"Return all text messages where age is discussed.\"\n",
        "  \"Find any message where one person asks another about their age.\"\n",
        "  \"Find messages where someone expresses a desire to harm another person.\"\n",
        "  \"Extract messages where anyone mentions planning something bad.\"\n",
        "  \"Show all conversations where someone discusses how an act was carried out.\"\n",
        "\n",
        "  Now generate 100 investigative questions following these guidelines.\n",
        "  \"\"\"\n",
        "  return prompt_text"
      ],
      "metadata": {
        "id": "-PjLzXjfjYOz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, gemini_model):\n",
        "  response = gemini_model.generate_content(contents=prompt)\n",
        "  questions = [line.strip() for line in response.text.strip().split(\"\\n\") if line.strip()]\n",
        "  return questions"
      ],
      "metadata": {
        "id": "5X5fS-Dcjbto"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ground_truth(generation_file): # Not required\n",
        "  pass"
      ],
      "metadata": {
        "id": "TlJjh-0OjiBr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_as_csv(questions, filename=\"investigative_questions.csv\"):\n",
        "  with open(filename, 'w', newline=\"\") as f:\n",
        "    writer= csv.writer(f)\n",
        "    # writer.writerow([\"Question\"])\n",
        "\n",
        "    for question in questions:\n",
        "      writer.writerow([question])\n",
        "\n",
        "  print(f\"Generated questions saved to {filename}\")"
      ],
      "metadata": {
        "id": "ZB5SJi84joPW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = prompt()\n",
        "questions = generate(prompt_text, gemini_model)\n",
        "questions\n",
        "save_as_csv(questions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xpJDEhwMAPWB",
        "outputId": "3995a8a8-88a2-4dae-f0ce-d40502840de8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated questions saved to investigative_questions.csv\n"
          ]
        }
      ]
    }
  ]
}